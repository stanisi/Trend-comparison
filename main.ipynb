{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"e5d31605-65d9-44a8-806c-4e99c8e43b7d\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    function drop(id) {\n      const view = Bokeh.index.get_by_id(id)\n      if (view != null) {\n        view.model.document.clear()\n        Bokeh.index.delete(view)\n      }\n    }\n\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n\n    // Clean up Bokeh references\n    if (id != null) {\n      drop(id)\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim()\n            drop(id)\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"e5d31605-65d9-44a8-806c-4e99c8e43b7d\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.4.0.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"e5d31605-65d9-44a8-806c-4e99c8e43b7d\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# from google_auth_oauthlib.flow import Flow\n",
    "# from IPython.display import Javascript\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "# import ipywidgets as widgets\n",
    "import statsmodels.api as sm\n",
    "import statsmodels\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import itertools\n",
    "from datetime import datetime, timedelta\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_notebook, output_file\n",
    "from bokeh.models import DaysTicker, FuncTickFormatter, ColumnDataSource, LabelSet, NumeralTickFormatter, DataTable, TableColumn, Div, HoverTool, Legend\n",
    "from bokeh.layouts import gridplot, layout\n",
    "from bokeh.transform import dodge\n",
    "from bokeh.palettes import cividis\n",
    "from bokeh.models.glyphs import Scatter\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller, kpss, acf, pacf, grangercausalitytests\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "from oauth2client import client\n",
    "from oauth2client import file\n",
    "from oauth2client import tools\n",
    "from google.oauth2 import service_account\n",
    "from apiclient.discovery import build\n",
    "import httplib2\n",
    "\n",
    "import numpy as np\n",
    "from bokeh.io import show, output_file\n",
    "from bokeh.plotting import figure\n",
    "\n",
    "output_notebook()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_df = (datetime.today() - timedelta(365*2)).strftime('%Y-%m-%d')\n",
    "end_dt = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# read clients csv\n",
    "acc = pd.read_csv('clients.csv')\n",
    "\n",
    "#Sessions\n",
    "df = pd.DataFrame(index = pd.date_range(freq = '1d', start = start_df, end = end_dt))\n",
    "# GoalCompletions\n",
    "df1 = pd.DataFrame(index = pd.date_range(freq = '1d', start = start_df, end = end_dt))\n",
    "\n",
    "for n in range(len(acc)):\n",
    "  try:\n",
    "    r = requests.get('https://www.googleapis.com/analytics/v3/data/ga?ids=ga%3A' + str(acc['GA View Id'][n]) + '&start-date=' + start_df + '&end-date=' + end_dt + '&metrics=ga%3Asessions%2Cga%3AgoalCompletionsAll&dimensions=ga%3Adate&filters=ga%3Asource%3D%3Dgoogle%3Bga%3Amedium%3D%3Dorganic&access_token=' + tokens.get('access_token')) # make the request # removing segmet temporarily &segment=gaid::PCfSbG2jQ5i1K2dIn82OoQ\n",
    "    data = r.json()\n",
    "\n",
    "    temp_df = pd.DataFrame(data['rows'])[[1]]\n",
    "    df[acc['Website Name'][n]] = temp_df[[1]].values\n",
    "    \n",
    "    temp_df1 = pd.DataFrame(data['rows'])[[2]]\n",
    "    df1[acc['Website Name'][n]] = temp_df[[2]].values\n",
    "  except: KeyError\n",
    "\n",
    "def norm(df):\n",
    "  # df = df.astype('int').diff().dropna() # differencing the data since it's not stationary; added 3/8\n",
    "  df_scaled_seasonal = pd.DataFrame(index = pd.date_range(freq = '1d', start = start_df, end = end_dt))\n",
    "  df_scaled_trend = pd.DataFrame(index = pd.date_range(freq = '1d', start = start_df, end = end_dt))\n",
    "  for i in range(df.shape[1]):\n",
    "    decomposition = sm.tsa.seasonal_decompose(pd.DataFrame(df.iloc[:, i].astype('int')), model='additive')\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "    scaled_x_seasonal = min_max_scaler.fit_transform(decomposition.seasonal.values.reshape(-1, 1))\n",
    "    df_scaled_seasonal[df.iloc[:, i].name] = scaled_x_seasonal\n",
    "\n",
    "    scaled_x_trend = min_max_scaler.fit_transform(decomposition.trend.values.reshape(-1, 1))\n",
    "    df_scaled_trend[df.iloc[:, i].name] = scaled_x_trend\n",
    "  return df_scaled_seasonal, df_scaled_trend\n",
    "\n",
    "\n",
    "def calc_trends(df, df_scaled_seasonal, df_scaled_trend):\n",
    "  # df_scaled_seasonal, df_scaled_trend = norm(df)\n",
    "  col0 = []\n",
    "  col1 = []\n",
    "  col2 = []\n",
    "\n",
    "  for i in range(df_scaled_seasonal.shape[1]):\n",
    "    for j in range(df_scaled_seasonal.shape[1]):\n",
    "      col0.append(df_scaled_seasonal.iloc[:,i].name)\n",
    "      col1.append(df_scaled_seasonal.iloc[:,j].name)\n",
    "      col2.append(sum(abs(df_scaled_seasonal.iloc[:,i] - df_scaled_seasonal.iloc[:,j])))\n",
    "\n",
    "  col3 = []\n",
    "  col4 = []\n",
    "  col5 = []\n",
    "  col6 = []\n",
    "  col7 = []\n",
    "  col8 = []\n",
    "  col9 = []\n",
    "  col10 = []\n",
    "\n",
    "  df_scaled_trend.dropna(inplace=True)\n",
    "  for i in range(df_scaled_trend.shape[1]):\n",
    "    for j in range(df_scaled_trend.shape[1]):\n",
    "      col3.append(df_scaled_trend.iloc[:,i].name)\n",
    "      col4.append(df_scaled_trend.iloc[:,j].name)\n",
    "      col5.append(sum(abs(df_scaled_trend.iloc[:,i] - df_scaled_trend.iloc[:,j])))\n",
    "      col6.append(sum(abs(df_scaled_trend.iloc[-31:,i] - df_scaled_trend.iloc[-31:,j])))\n",
    "      res = grangercausalitytests(df_scaled_trend.iloc[:, [i, j]], maxlag = 2, verbose = False)\n",
    "      col7.append(res[1][0]['lrtest'][1]) # p-value of 1st lag likelihood ratio test\n",
    "      col8.append(res[2][0]['lrtest'][1]) # p-value of 2nd lag likelihood ratio test\n",
    "      res2 = grangercausalitytests(df_scaled_trend.iloc[-31:, [i, j]], maxlag = 2, verbose = False)\n",
    "      col9.append(res2[1][0]['lrtest'][1]) # p-value of 1st lag likelihood ratio test\n",
    "      col10.append(res2[2][0]['lrtest'][1]) # p-value of 2nd lag likelihood ratio test\n",
    "\n",
    "\n",
    "  df_x = pd.DataFrame(zip(col0, col1, col2), columns=['Client_A', 'Client_B', 'Seasonal_score'])\n",
    "  df_y = pd.DataFrame(zip(col3, col4, col5, col6, col7, col8, col9, col10), columns=['Client_A', 'Client_B', 'Trend_score', 'Trend_score_1mo', 'LR_p', 'LR_p2', 'LR_p_1mo', 'LR_p2_1mo'])\n",
    "  df_merged = df_x.merge(df_y, how = 'inner', on=['Client_A', 'Client_B'])\n",
    "\n",
    "  df_merged = df_merged.loc[df_merged['Client_A'] != df_merged['Client_B']]\n",
    "\n",
    "  # df_merged['Sim_seasonal'] = [(1 - i / 40) * 0.15 if i <= 40 else 0 for i in df_merged['Seasonal_score']]\n",
    "  # df_merged['Sim_trend'] = [(1 - i / 80) * 0.10 if i <= 80 else 0 for i in df_merged['Trend_score']]\n",
    "  # df_merged['Sim_trend_1mo'] = [(1 - i / 20) * 0.15 if i <= 20 else 0 for i in df_merged['Trend_score_1mo']]\n",
    "  # df_merged['Sim_LR_p'] = [(1 - i / 0.05) * 0.15 if i <= 0.05 else 0 for i in df_merged['LR_p']]\n",
    "  # df_merged['Sim_LR_p2'] = [(1 - i / 0.05) * 0.15 if i <= 0.05 else 0 for i in df_merged['LR_p2']]\n",
    "  # df_merged['Sim_LR_p_1mo'] = [(1 - i / 0.05) * 0.05 if i <= 0.05 else 0 for i in df_merged['LR_p_1mo']]     #latest added signal, maybe adjust weight\n",
    "  # df_merged['Sim_LR_p2_1mo'] = [(1 - i / 0.05) * 0.05 if i <= 0.05 else 0 for i in df_merged['LR_p2_1mo']]   #latest added signal, maybe adjust weight\n",
    "\n",
    "  # df_merged['Sim_tot'] = df_merged['Sim_seasonal'] + df_merged['Sim_trend'] + df_merged['Sim_trend_1mo'] + df_merged['Sim_LR_p'] + df_merged['Sim_LR_p2'] + df_merged['Sim_LR_p_1mo'] + df_merged['Sim_LR_p2_1mo']\n",
    "  \n",
    "  return df_merged\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_scaled_seasonal, df_scaled_trend = norm(df)\n",
    "df_merged = calc_trends(df, df_scaled_seasonal, df_scaled_trend)\n",
    "\n",
    "SCOPES = ['https://www.googleapis.com/auth/webmasters.readonly']\n",
    "# hardcoding credentials to avoid having to authenticate to a google drive file\n",
    "SERVICE_ACCOUNT_FILE = 'service_account_file.json'\n",
    "\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "        SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
    "\n",
    "webmasters_service = build('searchconsole', 'v1', credentials = credentials)\n",
    "\n",
    "\n",
    "start_df0 = (datetime.today() - timedelta(365)).strftime('%Y-%m-%d')\n",
    "end_dt0 = (datetime.today() - timedelta(3)).strftime('%Y-%m-%d')\n",
    "df1 = pd.DataFrame(index = pd.date_range(freq = '1d', start = start_df0, end = end_dt0))\n",
    "df2 = pd.DataFrame(index = pd.date_range(freq = '1d', start = start_df0, end = end_dt0))\n",
    "df3 = pd.DataFrame(index = pd.date_range(freq = '1d', start = start_df0, end = end_dt0))\n",
    "\n",
    "# legacy api call\n",
    "for n in range(len(acc)):\n",
    "  try:\n",
    "    r1 = webmasters_service.searchanalytics().query(\n",
    "      siteUrl = acc['URL'][n] , body = {\n",
    "                                      'startDate': start_df0,\n",
    "                                      'endDate': end_dt0,\n",
    "                                      'dimensions': ['date'],\n",
    "                                      'rowLimit': 25000\n",
    "                                      }\n",
    "                                                ).execute()\n",
    "    temp_df1 = pd.DataFrame(r1['rows'])\n",
    "    temp_df1.columns = ['Date', 'Clicks', 'Impressions', 'CTR', 'Position']\n",
    "\n",
    "    for i in range(len(temp_df1['Date'])):\n",
    "      temp_df1['Date'][i] = temp_df1['Date'][i][0]\n",
    "\n",
    "    temp_df1 = temp_df1.iloc[:, [0, -1]] #Position\n",
    "    df1[acc['Website Name'][n]] = temp_df1.iloc[:, 1].values\n",
    "\n",
    "    temp_df2 = pd.DataFrame(r1['rows'])\n",
    "    temp_df2.columns = ['Date', 'Clicks', 'Impressions', 'CTR', 'Position']\n",
    "\n",
    "    for i in range(len(temp_df2['Date'])):\n",
    "      temp_df2['Date'][i] = temp_df2['Date'][i][0]\n",
    "\n",
    "    temp_df2 = temp_df2.iloc[:, [0, 1]] #Clicks\n",
    "    df2[acc['Website Name'][n]] = temp_df2.iloc[:, 1].values\n",
    "\n",
    "    temp_df3 = pd.DataFrame(r1['rows'])\n",
    "    temp_df3.columns = ['Date', 'Clicks', 'Impressions', 'CTR', 'Position']\n",
    "\n",
    "    for i in range(len(temp_df3['Date'])):\n",
    "      temp_df3['Date'][i] = temp_df3['Date'][i][0]\n",
    "\n",
    "    temp_df3 = temp_df3.iloc[:, [0, 2]] #Impressions\n",
    "    df3[acc['Website Name'][n]] = temp_df3.iloc[:, 1].values\n",
    "  except: requests.HTTPError\n",
    "\n",
    "# Function definitions\n",
    "def data_transform(df, start_date, end_date):\n",
    "    col0 = []\n",
    "    col1 = []\n",
    "    col2 = []\n",
    "\n",
    "\n",
    "    for s in range(df.shape[1]):\n",
    "      col0.append(df.iloc[:,s].name)\n",
    "      # period_len = min(len(df.iloc[:,s].loc[:start_date,]), len(df.iloc[:,s].loc[start_date:,])) #legacy code before adding end_date\n",
    "      period_len = len(df.iloc[:,s].loc[start_date:end_date,])\n",
    "      before_df = df.iloc[:,s].loc[:(pd.to_datetime(start_date) - timedelta(1)).strftime('%Y-%m-%d'),].iloc[-period_len+1:,]\n",
    "      after_df = df.iloc[:,s].loc[(pd.to_datetime(start_date) + timedelta(1)).strftime('%Y-%m-%d'):,].iloc[:period_len,]\n",
    "      col1.append(np.median(before_df.astype('int')))  # changed aggregation from mean to median 2021-08-17\n",
    "      col2.append(np.median(after_df.astype('int')))   # changed aggregation from mean to median 2021-08-17\n",
    "      # df.iloc[:,s].loc[:start_date,]\n",
    "\n",
    "    df_comp = pd.DataFrame(zip(col0, col1, col2), columns=['Client', 'Median before', 'Median after'])\n",
    "    df_comp['Difference'] = df_comp['Median after'] / df_comp['Median before'] - 1 \n",
    "    df_comp\n",
    "\n",
    "    # Error handling when division by zero or missing data for one of the periods for a client\n",
    "    df_comp.loc[~np.isfinite(df_comp['Difference']), 'Difference'] = np.nan\n",
    "    df_comp = df_comp.loc[-df_comp['Difference'].isnull()]\n",
    "\n",
    "\n",
    "    col3 = []\n",
    "    col4 = []\n",
    "    col5 = []\n",
    "\n",
    "    for s in range(df_scaled_trend.shape[1]):\n",
    "      col3.append(df_scaled_trend.iloc[:,s].name)\n",
    "      \n",
    "      # period_len = min(len(df_scaled_trend.iloc[:,s].loc[:start_date,]), len(df_scaled_trend.iloc[:,s].loc[start_date:,])) #legacy code before adding end_date\n",
    "      eriod_len = len(df_scaled_trend.iloc[:,s].loc[start_date:end_date,])\n",
    "      before_df = df_scaled_trend.iloc[:,s].loc[:(pd.to_datetime(start_date) - timedelta(1)).strftime('%Y-%m-%d'),].iloc[-period_len+1:,].astype('float64')\n",
    "      after_df = df_scaled_trend.iloc[:,s].loc[(pd.to_datetime(start_date) + timedelta(1)).strftime('%Y-%m-%d'):,].iloc[:period_len,].astype('float64')\n",
    "\n",
    "      X_before = (before_df.index -  before_df.index[0]).days.values.reshape(-1, 1)\n",
    "      Y_before = before_df.values\n",
    "      LIN_before = LinearRegression()\n",
    "      LIN_before.fit(X_before, Y_before)\n",
    "\n",
    "      X_after = (after_df.index -  after_df.index[0]).days.values.reshape(-1, 1)\n",
    "      Y_after = after_df.values\n",
    "      LIN_after = LinearRegression()\n",
    "      LIN_after.fit(X_after, Y_after)\n",
    "\n",
    "      col4.append(LIN_before.coef_[0])\n",
    "      col5.append(LIN_after.coef_[0])\n",
    "      # df.iloc[:,s].loc[:start_date,]\n",
    "\n",
    "    df_comp_slope = pd.DataFrame(zip(col3, col4, col5), columns=['Client', 'LR Slope before', 'LR Slope after'])\n",
    "    df_comp_slope['Difference'] = df_comp_slope['LR Slope after'] / df_comp_slope['LR Slope before'] - 1\n",
    "    return df_comp, df_comp_slope\n",
    "\n",
    "\n",
    "\n",
    "def plot_hist(df_comp, n_bins, client):\n",
    "    hist, edges = np.histogram(df_comp['Difference'], density=False, bins=n_bins)\n",
    "\n",
    "    p0 = figure(height = 300, width = 700)\n",
    "    p0.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:], line_color=\"white\", fill_color = '#00b5e2')\n",
    "    p0.title.text = \"Median change\"\n",
    "\n",
    "    if client != 'None':\n",
    "      selected_client_bin = df_comp[df_comp['Client'] == client]['Difference'].values[0]\n",
    "      glyph = Scatter(x=selected_client_bin, y=1, marker=\"square\", size = 10, fill_color = 'orange')\n",
    "      p0.add_glyph(glyph)\n",
    "\n",
    "    outliers = df_comp.loc[(df_comp['Difference'] < - 3*df_comp['Difference'].std()) | (df_comp['Difference'] > 3*df_comp['Difference'].std())]\n",
    "    outliers.iloc[:,1] = outliers.iloc[:,1].map(\"{:.2f}\".format)\n",
    "    outliers.iloc[:,2] = outliers.iloc[:,2].map(\"{:.2f}\".format)\n",
    "    outliers['Difference'] = outliers['Difference'].map(\"{:.2%}\".format)\n",
    "\n",
    "    p1 = DataTable(columns = [TableColumn(field=col, title=col) for col in outliers.columns], source = ColumnDataSource(outliers), height = 300, width = 450)\n",
    "    p2 = DataTable(columns = [TableColumn(field=col, title=col) for col in df_comp.columns], source = ColumnDataSource(df_comp), height = 500, width = 750)\n",
    "\n",
    "    p = gridplot([[p0, p1], [p2]])\n",
    "    output_file(\"hist.html\")\n",
    "    show(p)\n",
    "\n",
    "def plot_grid(df_comp1, df_comp2, df_comp3, n_bins, client):\n",
    "    hist1, edges1 = np.histogram(df_comp1['Difference'], density=False, bins=n_bins)\n",
    "    p1 = figure(height = 300, width = 700)\n",
    "    p1.quad(top=hist1, bottom=0, left=edges1[:-1], right=edges1[1:], line_color=\"white\", fill_color = '#00b5e2')\n",
    "    p1.title.text = \"Position - median change\"\n",
    "\n",
    "    if client != 'None':\n",
    "      selected_client_bin1 = df_comp1[df_comp1['Client'] == client]['Difference'].values[0]\n",
    "      glyph1 = Scatter(x=selected_client_bin1, y=1, marker=\"square\", size = 10, fill_color = 'orange')\n",
    "      p1.add_glyph(glyph1)\n",
    "\n",
    "\n",
    "    hist2, edges2 = np.histogram(df_comp2['Difference'], density=False, bins=n_bins)\n",
    "    p2 = figure(height = 300, width = 700)\n",
    "    p2.quad(top=hist2, bottom=0, left=edges2[:-1], right=edges2[1:], line_color=\"white\", fill_color = '#00b5e2')\n",
    "    p2.title.text = \"Clicks - median change\"\n",
    "\n",
    "    if client != 'None':\n",
    "      selected_client_bin2 = df_comp2[df_comp2['Client'] == client]['Difference'].values[0]\n",
    "      glyph2 = Scatter(x=selected_client_bin2, y=1, marker=\"square\", size = 10, fill_color = 'orange')\n",
    "      p2.add_glyph(glyph2)\n",
    "\n",
    "\n",
    "    hist3, edges3 = np.histogram(df_comp3['Difference'], density=False, bins=n_bins)\n",
    "    p3 = figure(height = 300, width = 700)\n",
    "    p3.quad(top=hist3, bottom=0, left=edges3[:-1], right=edges3[1:], line_color=\"white\", fill_color = '#00b5e2')\n",
    "    p3.title.text = \"Impressions - median change\"\n",
    "\n",
    "    if client != 'None':\n",
    "      selected_client_bin3 = df_comp3[df_comp3['Client'] == client]['Difference'].values[0]\n",
    "      glyph3 = Scatter(x=selected_client_bin3, y=1, marker=\"square\", size = 10, fill_color = 'orange')\n",
    "      p3.add_glyph(glyph3)\n",
    "\n",
    "\n",
    "    outliers1 = df_comp1.loc[(df_comp1['Difference'] < - 3*df_comp1['Difference'].std()) | (df_comp1['Difference'] > 3*df_comp1['Difference'].std())]\n",
    "    outliers1.iloc[:,1] = outliers1.iloc[:,1].map(\"{:.2f}\".format)\n",
    "    outliers1.iloc[:,2] = outliers1.iloc[:,2].map(\"{:.2f}\".format)\n",
    "    outliers1['Difference'] = outliers1['Difference'].map(\"{:.2%}\".format)\n",
    "    p1_1 = DataTable(columns = [TableColumn(field=col, title=col) for col in outliers1.columns], source = ColumnDataSource(outliers1), height = 300, width = 450)\n",
    "\n",
    "    outliers2 = df_comp2.loc[(df_comp2['Difference'] < - 3*df_comp2['Difference'].std()) | (df_comp2['Difference'] > 3*df_comp2['Difference'].std())]\n",
    "    outliers2.iloc[:,1] = outliers2.iloc[:,1].map(\"{:.2f}\".format)\n",
    "    outliers2.iloc[:,2] = outliers2.iloc[:,2].map(\"{:.2f}\".format)\n",
    "    outliers2['Difference'] = outliers2['Difference'].map(\"{:.2%}\".format)\n",
    "    p2_1 = DataTable(columns = [TableColumn(field=col, title=col) for col in outliers2.columns], source = ColumnDataSource(outliers2), height = 300, width = 450)\n",
    "\n",
    "    outliers3 = df_comp3.loc[(df_comp3['Difference'] < - 3*df_comp3['Difference'].std()) | (df_comp3['Difference'] > 3*df_comp3['Difference'].std())]\n",
    "    outliers3.iloc[:,1] = outliers3.iloc[:,1].map(\"{:.2f}\".format)\n",
    "    outliers3.iloc[:,2] = outliers3.iloc[:,2].map(\"{:.2f}\".format)\n",
    "    outliers3['Difference'] = outliers3['Difference'].map(\"{:.2%}\".format)\n",
    "    p3_1 = DataTable(columns = [TableColumn(field=col, title=col) for col in outliers3.columns], source = ColumnDataSource(outliers3), height = 300, width = 450)\n",
    "\n",
    "    p = gridplot([[p1, p1_1], [p2, p2_1], [p3, p3_1]])\n",
    "    # p = gridplot([[p1], [p2], [p3]])\n",
    "    output_file(\"hist.html\")\n",
    "    show(p)\n",
    "\n",
    "def plot_datatables(df_comp1, df_comp2, df_comp3):\n",
    "    div1 = Div(text=\"\"\"Position change\"\"\", width=200, height=100)\n",
    "    p1_2 = DataTable(columns = [TableColumn(field=col, title=col) for col in df_comp1.columns], source = ColumnDataSource(df_comp1), height = 450, width = 400)\n",
    "\n",
    "    div2 = Div(text=\"\"\"Clicks change\"\"\", width=200, height=100)\n",
    "    p2_2 = DataTable(columns = [TableColumn(field=col, title=col) for col in df_comp2.columns], source = ColumnDataSource(df_comp2), height = 450, width = 400)\n",
    "\n",
    "    div3 = Div(text=\"\"\"Impressions change\"\"\", width=200, height=100)\n",
    "    p3_2 = DataTable(columns = [TableColumn(field=col, title=col) for col in df_comp3.columns], source = ColumnDataSource(df_comp3), height = 450, width = 400)\n",
    "\n",
    "    p2 = gridplot([[div1, div2, div3], [p1_2, p2_2, p3_2]])\n",
    "    # p = gridplot([[p1], [p2], [p3]])\n",
    "    # output_file(\"hist.html\")\n",
    "    show(p2)\n",
    "\n",
    "def print_summary(df_comp):\n",
    "  print('')\n",
    "  print('---------------------Summary--------------------')\n",
    "  period_len = pd.to_datetime(end_date) - pd.to_datetime(start_date)\n",
    "  print(f'Period length: {period_len}')\n",
    "  all = len(df_comp)\n",
    "  print(f'Total number of clients in the sample: {all}')\n",
    "  pos_len = len(df_comp.loc[df_comp['Difference'] >= 0])\n",
    "  print(f'Clients with positive change: {pos_len} ({\"{:.2%}\".format(pos_len/all)})')\n",
    "  neg_len = len(df_comp.loc[df_comp['Difference'] < 0])\n",
    "  print(f'Clients with negative change: {neg_len} ({\"{:.2%}\".format(neg_len/all)})')\n",
    "\n",
    "  print('')\n",
    "  print('---------------------Normal Distribution checks--------------------')\n",
    "  mean_diff = df_comp['Difference'].mean()\n",
    "  print(f'Mean difference: {\"{:.2}\".format(mean_diff)}')\n",
    "  median_diff = df_comp['Difference'].median()\n",
    "  print(f'Median difference: {\"{:.2}\".format(median_diff)}')\n",
    "  skewness = df_comp['Difference'].skew()\n",
    "  print(f'Skewness: {\"{:.2}\".format(skewness)} (Interpretation: -1: Skewed to the left, 0: Not skewed, 1: Skewed to the right)')\n",
    "  kurt = df_comp['Difference'].kurtosis()\n",
    "  print(f'Kurtosis: {\"{:.2}\".format(kurt)} (Interpretation: -1: Long tail(s), low middle point, 0: Standard bell shape, 1: short tail(s), high middle point)')\n",
    "\n",
    "  one_std = len(df_comp.loc[(df_comp['Difference'] >= -df_comp['Difference'].std()) & (df_comp['Difference'] < df_comp['Difference'].std())])\n",
    "  print(f'Data within 1 Standard Deviation from the mean: {one_std} ({\"{:.2%}\".format(one_std/all)})')\n",
    "  two_std = len(df_comp.loc[(df_comp['Difference'] >= - 2*df_comp['Difference'].std()) & (df_comp['Difference'] < 2*df_comp['Difference'].std())])\n",
    "  print(f'Data within 2 Standard Deviations from the mean: {two_std} ({\"{:.2%}\".format(two_std/all)})')\n",
    "  three_std = len(df_comp.loc[(df_comp['Difference'] >= - 3*df_comp['Difference'].std()) & (df_comp['Difference'] < 3*df_comp['Difference'].std())])\n",
    "  print(f'Data within 3 Standard Deviations from the mean: {three_std} ({\"{:.2%}\".format(three_std/all)})')\n",
    "\n",
    "  print('')\n",
    "  print('--------------------Outliers---------------------')\n",
    "  first_q = len(df_comp.loc[df_comp['Difference'] <= -0.5])\n",
    "  print(f'Clients with difference of less than -50%: {first_q} ({\"{:.2%}\".format(first_q/all)})')\n",
    "  fourth_q = first_q = len(df_comp.loc[df_comp['Difference'] > 0.5])\n",
    "  print(f'Clients with difference of more than 50%: {fourth_q} ({\"{:.2%}\".format(fourth_q/all)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Histograms\n",
    "* Distribution of clients on a histogram based on their median change before and after.\n",
    "* Having all clients on a single plot helps identify if a single big event (like google algorythm update) happened and in what way affected clients\n",
    "* We can mark a select a single client to map where they lie on the histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"d7ffb73f-148e-4497-8b8d-d02e939c582e\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    function drop(id) {\n      const view = Bokeh.index.get_by_id(id)\n      if (view != null) {\n        view.model.document.clear()\n        Bokeh.index.delete(view)\n      }\n    }\n\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n\n    // Clean up Bokeh references\n    if (id != null) {\n      drop(id)\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim()\n            drop(id)\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"d7ffb73f-148e-4497-8b8d-d02e939c582e\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.4.0.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"d7ffb73f-148e-4497-8b8d-d02e939c582e\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_notebook()\n",
    "\n",
    "import time\n",
    "\n",
    "start_date = '2022-05-01' #@param {type: \"date\"}\n",
    "end_date = '2022-06-30' #@param {type: \"date\"}\n",
    "n_bins =  20#@param {type:\"slider\", min:10, max:30, step:1}\n",
    "client = 'None'\n",
    "\n",
    "df_comp, df_comp_slope = data_transform(df, start_date, end_date)\n",
    "\n",
    "\n",
    "plot_hist(df_comp, n_bins, client)\n",
    "print_summary(df_comp)\n",
    "# print(df_comp.sort_values('Difference', ascending = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Goal Completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "\n",
    "import time\n",
    "\n",
    "start_date = '2022-05-26' #@param {type: \"date\"}\n",
    "end_date = '2022-06-27' #@param {type: \"date\"}\n",
    "n_bins =  20#@param {type:\"slider\", min:10, max:30, step:1}\n",
    "client = 'None'\n",
    "\n",
    "df_comp1, df_comp_slope1 = data_transform(df1, start_date, end_date)\n",
    "\n",
    "\n",
    "plot_hist(df_comp1, n_bins, client)\n",
    "print_summary(df_comp1)\n",
    "# print(df_comp.sort_values('Difference', ascending = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Search console data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "\n",
    "import time\n",
    "\n",
    "start_date = '2022-05-26' #@param {type: \"date\"}\n",
    "end_date = '2022-06-26' #@param {type: \"date\"}\n",
    "n_bins =  25#@param {type:\"slider\", min:10, max:30, step:1}\n",
    "client = 'None' \n",
    "\n",
    "df_comp1, df_comp_slope1 = data_transform(df1, start_date, end_date)\n",
    "df_comp2, df_comp_slope2 = data_transform(df2, start_date, end_date)\n",
    "df_comp3, df_comp_slope3 = data_transform(df3, start_date, end_date)\n",
    "\n",
    "plot_grid(df_comp1, df_comp2, df_comp3, n_bins, client)\n",
    "plot_datatables(df_comp1, df_comp2, df_comp3)\n",
    "print_summary(df_comp1)\n",
    "print_summary(df_comp2)\n",
    "print_summary(df_comp3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
